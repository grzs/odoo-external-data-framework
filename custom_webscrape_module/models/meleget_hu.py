# coding: utf-8
import re
import requests as req
from time import strptime, mktime
from datetime import datetime
from bs4 import BeautifulSoup as bs

from odoo import models, api


class WebscrapeScraperMelegetHu(models.Model):
    _name = 'webscrape.scraper.meleget.hu'
    _description = "meleget.hu"

    @api.model
    def process_sitemap(self, base_url, not_before=False):
        """Parsing <base_url>/sitemap.xml (generated by Google)
        with BeautifulSoup xml parser. Returns a list of dictionaries."""

        # sanitize base_url and compose sitemap_url
        base_url = re.match('https?://[^/]+', base_url).group()
        sitemap_url = '/'.join([base_url, 'sitemap.xml'])

        # download sitemap and create bs object
        sitemap = bs(req.get(sitemap_url).text, 'xml')

        time_pattern = '%Y-%m-%dT%H:%M:%S%z'
        pages = []
        for page in sitemap.contents[0].children:
            last_mod = (datetime.fromtimestamp(
                mktime(strptime(page.lastmod.text, time_pattern)))
                if page.lastmod else None
                )
            if not_before and last_mod and not_before > last_mod:
                continue
            path = page.loc.text[len(base_url):].split('/')
            pages.append({
                "url": page.loc.text,
                "level": len(path),
                "changefreq":
                page.changefreq.text if page.changefreq else None,
                "priority":
                float(page.priority.text) if page.priority else None,
                "last_mod": last_mod,
            })
        return pages

    @api.model
    def scrape_page(self, url, **kwargs):
        """Parsing a webpage passed in a 'page' object. Returns parsed data.
        """

        # scrape page with BeautifulSoup
        soup = bs(req.get(url).text, "lxml")
        base_url = re.match('https?://[^/]+', url).group()
        data = []

        # opengraph
        # meta_og_type = soup.head.find("meta", property="og:type")

        # breadcrumbs (=categories)
        bc_parent = None
        for bc in self._breadcrumbs(
                soup.body.find(itemtype='http://schema.org/BreadcrumbList')
        ):
            href = bc.get("item")
            if not href or href == url or href == base_url:
                continue

            data.append({
                "content_type": "category",
                "vals": {
                    "href": href,
                    "name": bc.get("name"),
                    "parent_href": bc_parent,
                },
                "relations": {
                    "parent_category": {
                        "content_type": "category",
                        "source_id": bc_parent,
                    } if bc_parent else False,
                },
            })
            bc_parent = href
        last_category_href = data[-1]["vals"]["href"] if data else False

        # append specific data objects to list
        if soup.find(itemtype='//schema.org/Product'):
            data.append({
                "content_type": "product",
                "vals": self._parse_product_data(soup),
                "relations": {
                    "category": {
                        "content_type": "category",
                        "source_id": last_category_href,
                    } if last_category_href else False,
                },
            })

        # TODO: attachments
        # attachment_list = list(
        #     self._attachment_list(soup.select_one("div.attached_documents"))
        # )

        # TODO: parse parameter table as product attributes
        # parameter_table = list(self._parse_parameter_table(soup))

        return data

    @api.model
    def _parse_product_data(self, soup):
        res = {}

        schemaorg_product = soup.find(itemtype='//schema.org/Product')
        product_props = [
            ("name", "string"),
            ("description", "tag"),
            ("brand", "string"),
            ("sku", "content"),
            ("image", "src"),
        ]
        for p in product_props:
            if p[1] == "string":
                val = schemaorg_product.findChild(itemprop=p[0]).string.strip()
            elif p[1] == "tag":
                val = str(schemaorg_product.findChild(itemprop=p[0]))
            else:
                val = schemaorg_product.findChild(itemprop=p[0])[p[1]]
            res[p[0]] = val if val else None

        # price, availability
        schemaorg_offer = soup.find(itemtype='//schema.org/Offer')
        price_original = soup.select_one("span.product_table_original")
        try:
            offer_props = [
                ("pricecurrency", "content"),
                ("price", "content"),
                ("availability", "href"),
                ("category", "content"),
            ]
            for p in offer_props:
                val = schemaorg_offer.findChild(itemprop=p[0]).get(p[1])
                res[p[0]] = val if val else None

            if price_original:
                found = re.findall('[0-9]+', price_original.string)
                res.update(price_original=''.join(found) if found else None)
        except AttributeError as e:
            print(e)
            # TODO: log error "'NoneType' object has no attribute 'findChild'"
            addtocart_a = soup.find("a", id="add_to_cart")
            if addtocart_a:
                res.update({
                    "price": addtocart_a.get("data-price-without-currency"),
                    "pricecurrency": addtocart_a.get("data-currency"),
                })

        return res

    @api.model
    def _parameter_table(self, soup):
        param_table = soup.body.select_one("table.parameter_table")
        if not param_table:
            return False

        for row in param_table.findChildren("tr"):
            cells = row.findChildren("td")
            if not cells[0].string:
                continue
            yield {
                cells[0].string.strip():
                cells[1].string.strip() if cells[1].string else None,
            }

    @api.model
    def _attachment_list(self, bs_list):
        if not bs_list:
            return False

        for a in bs_list.find_all("a"):
            yield {
                "name": a.string.strip(),
                "url": a["href"],
            }

    @api.model
    def _breadcrumbs(self, bs_breadcrumbs):
        if (
                not bs_breadcrumbs or
                bs_breadcrumbs['itemtype'] !=
                'http://schema.org/BreadcrumbList'
        ):
            return False

        for elem in bs_breadcrumbs.find_all(itemprop="itemListElement"):
            yield {
                "item": elem.find(itemprop="item")["href"],
                "name": elem.find(itemprop="name").string.strip(),
                "position": int(elem.find(itemprop="position")["content"]),
            }
